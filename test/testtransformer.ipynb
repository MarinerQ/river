{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "blocked-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "# helpers\n",
    "\n",
    "def posemb_sincos_1d(patches, temperature = 10000, dtype = torch.float32):\n",
    "    _, n, dim, device, dtype = *patches.shape, patches.device, patches.dtype\n",
    "\n",
    "    n = torch.arange(n, device = device)\n",
    "    assert (dim % 2) == 0, 'feature dimension must be multiple of 2 for sincos emb'\n",
    "    omega = torch.arange(dim // 2, device = device) / (dim // 2 - 1)\n",
    "    omega = 1. / (temperature ** omega)\n",
    "\n",
    "    n = n.flatten()[:, None] * omega[None, :]\n",
    "    pe = torch.cat((n.sin(), n.cos()), dim = 1)\n",
    "    return pe.type(dtype)\n",
    "\n",
    "# classes\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "        self.to_out = nn.Linear(inner_dim, dim, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Attention(dim, heads = heads, dim_head = dim_head),\n",
    "                FeedForward(dim, mlp_dim)\n",
    "            ]))\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return self.norm(x)\n",
    "\n",
    "class SimpleViT(nn.Module):\n",
    "    def __init__(self, *, seq_len, patch_size, num_classes, dim, depth, heads, mlp_dim, channels = 3, dim_head = 64):\n",
    "        super().__init__()\n",
    "\n",
    "        assert seq_len % patch_size == 0\n",
    "\n",
    "        num_patches = seq_len // patch_size\n",
    "        patch_dim = channels * patch_size\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (n p) -> b n (p c)', p = patch_size),\n",
    "            nn.LayerNorm(patch_dim),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "            nn.LayerNorm(dim),\n",
    "        )\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim)\n",
    "\n",
    "        self.to_latent = nn.Identity()\n",
    "        self.linear_head = nn.Linear(dim, num_classes)\n",
    "\n",
    "    def forward(self, series):\n",
    "        *_, n, dtype = *series.shape, series.dtype\n",
    "\n",
    "        x = self.to_patch_embedding(series)\n",
    "        pe = posemb_sincos_1d(x)\n",
    "        x = rearrange(x, 'b ... d -> b (...) d') + pe\n",
    "        print(x.shape)\n",
    "        x = self.transformer(x)\n",
    "        print(x.shape)\n",
    "        x = x.mean(dim = 1)\n",
    "        print(x.shape)\n",
    "\n",
    "        x = self.to_latent(x)\n",
    "        print(x.shape)\n",
    "        return self.linear_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "domestic-fence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleViT2(nn.Module):\n",
    "    def __init__(self, *, seq_len, patch_size, num_classes, dim, depth, heads, mlp_dim, channels = 3, dim_head = 64, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        assert seq_len % patch_size == 0\n",
    "\n",
    "        num_patches = seq_len // patch_size\n",
    "        patch_dim = channels * patch_size\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (n p) -> b n (p c)', p = patch_size),\n",
    "            nn.LayerNorm(patch_dim),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "            nn.LayerNorm(dim),\n",
    "        )\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim)\n",
    "\n",
    "        self.to_latent = nn.Identity()\n",
    "        self.linear_head = nn.Linear(dim*num_patches, num_classes)\n",
    "\n",
    "    def forward(self, series):\n",
    "        *_, n, dtype = *series.shape, series.dtype\n",
    "        \n",
    "        x = self.to_patch_embedding(series)\n",
    "        pe = posemb_sincos_1d(x)\n",
    "        x = rearrange(x, 'b ... d -> b (...) d') + pe\n",
    "\n",
    "        x = self.transformer(x)\n",
    "        return x\n",
    "        #x = x.mean(dim = 1)\n",
    "        #x = x.flatten(1,2)\n",
    "        ##x = self.to_latent(x)\n",
    "        return self.linear_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "unusual-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = SimpleViT2(\n",
    "        seq_len = 3328,\n",
    "        patch_size = 256,\n",
    "        num_classes = 256,\n",
    "        dim = 128,\n",
    "        depth = 6,\n",
    "        heads = 8,\n",
    "        mlp_dim = 2048,\n",
    "        channels = 6, \n",
    "        dim_head = 64,\n",
    "    ).to('cuda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "nutritional-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10) + torch.randn(10)*1j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "tutorial-headquarters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0688, -1.8898,  0.4153, -0.4304,  0.3556,  0.0640, -1.0887, -1.0803,\n",
       "         0.4693,  1.3235, -0.4128, -0.5735,  1.2037,  0.7315, -0.8733, -0.3219,\n",
       "        -0.2529,  1.4177,  2.1978, -0.0811])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x.real, x.imag)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-signature",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "closed-publication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 10])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff.repeat((6,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "graduate-haiti",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2239, -2.1005, -0.2320, -1.4094,  0.4021,  0.7713,  0.8216,  1.7990,\n",
       "        -0.3338, -3.4558])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "abandoned-warehouse",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cat() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-e85cf9003cd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cat() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "torch.cat((ff, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "grateful-scratch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2239, -2.1005, -0.2320, -1.4094,  0.4021,  0.7713,  0.8216,  1.7990,\n",
       "        -0.3338, -3.4558, -0.2239, -2.1005, -0.2320, -1.4094,  0.4021,  0.7713,\n",
       "         0.8216,  1.7990, -0.3338, -3.4558])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((ff,ff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "alleged-groove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2239, -2.1005, -0.2320, -1.4094,  0.4021,  0.7713,  0.8216,  1.7990,\n",
       "         -0.3338, -3.4558],\n",
       "        [-0.2239, -2.1005, -0.2320, -1.4094,  0.4021,  0.7713,  0.8216,  1.7990,\n",
       "         -0.3338, -3.4558],\n",
       "        [-0.2239, -2.1005, -0.2320, -1.4094,  0.4021,  0.7713,  0.8216,  1.7990,\n",
       "         -0.3338, -3.4558],\n",
       "        [-0.2239, -2.1005, -0.2320, -1.4094,  0.4021,  0.7713,  0.8216,  1.7990,\n",
       "         -0.3338, -3.4558],\n",
       "        [-0.2239, -2.1005, -0.2320, -1.4094,  0.4021,  0.7713,  0.8216,  1.7990,\n",
       "         -0.3338, -3.4558],\n",
       "        [-0.2239, -2.1005, -0.2320, -1.4094,  0.4021,  0.7713,  0.8216,  1.7990,\n",
       "         -0.3338, -3.4558]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff.repeat((6,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dramatic-vegetation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3328/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "accredited-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = torch.randn(1024, 6, 3328).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-place",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "false-lafayette",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = v(time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "vulnerable-improvement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 13, 128])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "great-journey",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "valued-argentina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "coun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "better-miller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1664"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "broad-lender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 256])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-compromise",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "successful-norman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr  9 07:05:39 2024       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  NVIDIA GeForce GTX 1650        Off |   00000000:02:00.0 Off |                  N/A |\r\n",
      "| 30%   23C    P8              4W /   75W |       2MiB /   4096MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   1  Tesla P40                      Off |   00000000:03:00.0 Off |                    0 |\r\n",
      "| N/A   23C    P8              9W /  250W |       2MiB /  23040MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   2  Tesla P100-PCIE-16GB           Off |   00000000:84:00.0 Off |                    0 |\r\n",
      "| N/A   20C    P0             31W /  250W |   10080MiB /  16384MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|    2   N/A  N/A    164902      C   .../.conda/envs/myigwn-py39/bin/python      10078MiB |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "devoted-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "miniature-belly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4968064"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "third-italy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5361280"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "generous-silver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000 * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-sudan",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spectacular-spouse",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/home/qian.hu/.local/lib/python3.9/site-packages/glue/ligolw/lsctables.py:50: UserWarning: Wswiglal-redir-stdio:\n",
      "\n",
      "SWIGLAL standard output/error redirection is enabled in IPython.\n",
      "This may lead to performance penalties. To disable locally, use:\n",
      "\n",
      "with lal.no_swig_redirect_standard_output_error():\n",
      "    ...\n",
      "\n",
      "To disable globally, use:\n",
      "\n",
      "lal.swig_redirect_standard_output_error(True)\n",
      "\n",
      "Note however that this will likely lead to error messages from\n",
      "LAL functions being either misdirected or lost when called from\n",
      "Jupyter notebooks.\n",
      "\n",
      "To suppress this warning, use:\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
      "import lal\n",
      "\n",
      "  import lal\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import bilby \n",
    "#import pycbc \n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import glob \n",
    "\n",
    "#import zuko\n",
    "from glasflow import RealNVP, CouplingNSF\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import river.data\n",
    "from river.data.datagenerator import DataGeneratorBilbyFD\n",
    "from river.data.dataset_multiband import DatasetMBStrainFDFromMBWFonGPU, DatasetMBStrainFDFromMBWFonGPUBatch\n",
    "#import river.data.utils as datautils\n",
    "from river.data.utils import *\n",
    "\n",
    "from river.models import embedding\n",
    "from river.models.utils import *\n",
    "from river.models.embedding.conv import EmbeddingConv1D, EmbeddingConv2D\n",
    "from river.models.embedding.mlp import EmbeddingMLP1D\n",
    "from river.models.inference.cnf import GlasNSFConv1DRes, GlasNSFConv1D, GlasNSFTest, GlasflowEmbdding\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fatal-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "config_path = '/home/qian.hu/mlpe/river/scripts/trained_models/BNS20MB_8M'\n",
    "with open(f\"{config_path}/config.json\", 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "config_datagenerator = config['data_generator_parameters']\n",
    "config_training = config['training_parameters']\n",
    "config_model = config['model_parameters']\n",
    "config_precaldata = config['precaldata_parameters']\n",
    "\n",
    "\n",
    "dmin = config_datagenerator['d_min']\n",
    "dmax = config_datagenerator['d_max']\n",
    "dpower = config_datagenerator['d_power']\n",
    "tc_min = config_datagenerator['tc_min']\n",
    "tc_max = config_datagenerator['tc_max']\n",
    "timing_std = config_datagenerator['timing_std']\n",
    "full_duration = config_datagenerator['full_duration']\n",
    "\n",
    "detector_names = config_datagenerator['detector_names']\n",
    "\n",
    "\n",
    "wf_folder_train = config_precaldata['train']['folder']\n",
    "wf_folder_valid = config_precaldata['valid']['folder']\n",
    "asd_folder = config_precaldata['asd_path']\n",
    "\n",
    "batch_size_train = config_training['batch_size_train']\n",
    "minibatch_size_train = config_training['minibatch_size_train']\n",
    "batch_size_valid = config_training['batch_size_valid']\n",
    "minibatch_size_valid = config_training['minibatch_size_valid']\n",
    "\n",
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "federal-alloy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.129700183868408\n"
     ]
    }
   ],
   "source": [
    "t1 =time.time()\n",
    "minibatch_size_train = 1024\n",
    "dataset_train = DatasetMBStrainFDFromMBWFonGPUBatch(wf_folder = config_precaldata['train']['folder'],\n",
    "                                                    asd_folder = asd_folder,\n",
    "                                                    parameter_names = PARAMETER_NAMES_CONTEXT_PRECESSINGBNS_BILBY, \n",
    "                                                    full_duration = full_duration, \n",
    "                                                    detector_names = detector_names,\n",
    "                                                    dmin = dmin,\n",
    "                                                    dmax = dmax,\n",
    "                                                    dpower = dpower, \n",
    "                                                    tc_min = tc_min,\n",
    "                                                    tc_max = tc_max,\n",
    "                                                    timing_std = timing_std,\n",
    "                                                    device = device,\n",
    "                                                    minibatch_size = minibatch_size_train,\n",
    "                                                    add_noise = True,\n",
    "                                                    fix_extrinsic = False,\n",
    "                                                    reparameterize = True,\n",
    "                                                    random_asd = False)\n",
    "t2 =time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "derived-child",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch_size_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sunrise-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 8192\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size_train // minibatch_size_train, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "billion-thomas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8192"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "municipal-vocabulary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1345620155334473 !\n",
      "0.2530670166015625 !\n",
      "1.597344160079956 !\n",
      "0.23201775550842285 !\n",
      "1.4167084693908691 !\n",
      "0.2352135181427002 !\n",
      "4.226032018661499 !\n",
      "3.6697959899902344 !\n",
      "1.3655133247375488 !\n",
      "0.26023006439208984 !\n",
      "0.2669806480407715 !\n",
      "3.169447183609009 !\n",
      "0.22391986846923828 !\n",
      "0.2427988052368164 !\n",
      "0.2726259231567383 !\n",
      "huh\n",
      "23.914116144180298 !\n",
      "0.2500483989715576 !\n",
      "0.277482271194458 !\n",
      "0.26161742210388184 !\n",
      "0.26476573944091797 !\n",
      "0.2657797336578369 !\n",
      "0.3048679828643799 !\n",
      "0.26399731636047363 !\n",
      "0.2325451374053955 !\n",
      "0.28082895278930664 !\n",
      "0.2776827812194824 !\n",
      "0.28624439239501953 !\n",
      "0.30045628547668457 !\n",
      "0.2827482223510742 !\n",
      "0.31584954261779785 !\n",
      "0.28054308891296387 !\n",
      "huh\n",
      "22.877390146255493 !\n",
      "0.25937867164611816 !\n",
      "0.26985979080200195 !\n",
      "0.27018117904663086 !\n",
      "0.2723073959350586 !\n",
      "0.28502464294433594 !\n",
      "8.500895500183105 !\n",
      "11.06877589225769 !\n",
      "0.2531454563140869 !\n",
      "0.27324461936950684 !\n",
      "0.3037087917327881 !\n",
      "0.34827566146850586 !\n",
      "0.29572415351867676 !\n",
      "0.24181008338928223 !\n",
      "0.24010896682739258 !\n",
      "0.2539408206939697 !\n",
      "huh\n",
      "29.136656045913696 !\n",
      "0.2703268527984619 !\n",
      "0.28262829780578613 !\n",
      "0.2762303352355957 !\n",
      "0.28137850761413574 !\n",
      "0.2791919708251953 !\n",
      "0.28469038009643555 !\n",
      "0.281660795211792 !\n",
      "0.26396822929382324 !\n",
      "0.27329134941101074 !\n",
      "0.28319215774536133 !\n",
      "0.25612878799438477 !\n",
      "0.2289443016052246 !\n",
      "0.23074817657470703 !\n",
      "0.2289416790008545 !\n",
      "0.2472362518310547 !\n",
      "huh\n",
      "21.7666437625885 !\n",
      "0.26609015464782715 !\n",
      "0.23894333839416504 !\n",
      "0.2542693614959717 !\n",
      "0.24029254913330078 !\n",
      "0.251096248626709 !\n",
      "0.2613236904144287 !\n",
      "0.2756316661834717 !\n",
      "0.3111152648925781 !\n",
      "0.2969930171966553 !\n",
      "0.2926015853881836 !\n",
      "0.2749450206756592 !\n",
      "0.3027975559234619 !\n",
      "0.28742170333862305 !\n",
      "0.2545192241668701 !\n",
      "0.2823822498321533 !\n",
      "huh\n",
      "21.85905933380127 !\n",
      "0.21762537956237793 !\n",
      "0.24591922760009766 !\n",
      "0.2575061321258545 !\n",
      "0.26266956329345703 !\n",
      "0.2547292709350586 !\n",
      "0.2607893943786621 !\n",
      "0.26839613914489746 !\n",
      "0.26099133491516113 !\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8bb007850898>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myigwn-py39/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myigwn-py39/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myigwn-py39/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myigwn-py39/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlpe/river/river/data/dataset_multiband.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m#    wf_dict_list.append(self.get_precalwf_dict(i))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mwf_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_precalwf_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_of_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_in_file_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mhp_mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhc_mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_waveform_tensors_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwf_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_in_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_in_file_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0minjection_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_injection_parameters_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwf_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_in_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_in_file_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0minjection_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_injection_parameters_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minjection_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlpe/river/river/data/dataset_multiband.py\u001b[0m in \u001b[0;36mget_waveform_tensors_batch\u001b[0;34m(self, wf_dict, index_in_file, index_in_file_end)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m#    hc = torch.cat((hc,hc_new))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'waveforms'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_p\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mhc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'waveforms'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tt = []\n",
    "\n",
    "t1 =time.time()\n",
    "for t,x in train_loader:\n",
    "    t2 =time.time()\n",
    "    tt.append(t2-t1)\n",
    "    print(t2-t1, '!')\n",
    "    t1 =time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-definition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "funded-boring",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset_train, train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "junior-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_path = '/home/qian.hu/mlpe/river/scripts/trained_models/BNS20MB_8M'\n",
    "with open(f\"{config_path}/config.json\", 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "config_datagenerator = config['data_generator_parameters']\n",
    "config_training = config['training_parameters']\n",
    "config_model = config['model_parameters']\n",
    "config_precaldata = config['precaldata_parameters']\n",
    "\n",
    "\n",
    "dmin = config_datagenerator['d_min']\n",
    "dmax = config_datagenerator['d_max']\n",
    "dpower = config_datagenerator['d_power']\n",
    "tc_min = config_datagenerator['tc_min']\n",
    "tc_max = config_datagenerator['tc_max']\n",
    "timing_std = config_datagenerator['timing_std']\n",
    "full_duration = config_datagenerator['full_duration']\n",
    "\n",
    "\n",
    "\n",
    "# Set up logger\n",
    "PID = os.getpid()\n",
    "device='cuda'\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n",
    "\n",
    "stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "stdout_handler.setLevel(logging.DEBUG)\n",
    "stdout_handler.setFormatter(formatter)\n",
    "\n",
    "ckpt_dir = 'test_train_output'\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.mkdir(ckpt_dir)\n",
    "    logger.warning(f\"{ckpt_dir} does not exist. Made dir {ckpt_dir}.\")\n",
    "\n",
    "logfilename = f\"{ckpt_dir}/logs.log\"\n",
    "file_handler = logging.FileHandler(logfilename)\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "ckpt_path = f'{ckpt_dir}/checkpoint.pickle'\n",
    "\n",
    "logger.info(f'PID={PID}.')\n",
    "logger.info(f'Output path: {ckpt_dir}')\n",
    "\n",
    "detector_names = config_datagenerator['detector_names']\n",
    "\n",
    "\n",
    "logger.info(f'Loading precalculated data.')\n",
    "wf_folder_train = config_precaldata['valid']['folder']\n",
    "wf_folder_valid = config_precaldata['valid']['folder']\n",
    "asd_folder = config_precaldata['asd_path']\n",
    "\n",
    "batch_size_train = config_training['batch_size_valid']\n",
    "minibatch_size_train = config_training['minibatch_size_valid']\n",
    "batch_size_valid = config_training['batch_size_valid']\n",
    "minibatch_size_valid = config_training['minibatch_size_valid']\n",
    "\n",
    "\n",
    "dataset_train = DatasetMBStrainFDFromMBWFonGPUBatch(wf_folder = wf_folder_train,\n",
    "                                                    asd_folder = asd_folder,\n",
    "                                                    parameter_names = PARAMETER_NAMES_CONTEXT_PRECESSINGBNS_BILBY, \n",
    "                                                    full_duration = full_duration, \n",
    "                                                    detector_names = detector_names,\n",
    "                                                    dmin = dmin,\n",
    "                                                    dmax = dmax,\n",
    "                                                    dpower = dpower, \n",
    "                                                    tc_min = tc_min,\n",
    "                                                    tc_max = tc_max,\n",
    "                                                    timing_std = timing_std,\n",
    "                                                    device = device,\n",
    "                                                    minibatch_size = minibatch_size_train,\n",
    "                                                    add_noise = True,\n",
    "                                                    fix_extrinsic = False,\n",
    "                                                    reparameterize = True,\n",
    "                                                    random_asd = False)\n",
    "\n",
    "dataset_valid = DatasetMBStrainFDFromMBWFonGPUBatch(wf_folder = wf_folder_valid,\n",
    "                                                    asd_folder = asd_folder,\n",
    "                                                    parameter_names = PARAMETER_NAMES_CONTEXT_PRECESSINGBNS_BILBY, \n",
    "                                                    full_duration = full_duration, \n",
    "                                                    detector_names = detector_names,\n",
    "                                                    dmin = dmin,\n",
    "                                                    dmax = dmax,\n",
    "                                                    dpower = dpower, \n",
    "                                                    tc_min = tc_min,\n",
    "                                                    tc_max = tc_max,\n",
    "                                                    timing_std = timing_std,\n",
    "                                                    device = device,\n",
    "                                                    minibatch_size = minibatch_size_train,\n",
    "                                                    add_noise = True,\n",
    "                                                    fix_extrinsic = False,\n",
    "                                                    reparameterize = True,\n",
    "                                                    random_asd = False)\n",
    "\n",
    "\n",
    "Nsample = len(dataset_train)*minibatch_size_train\n",
    "Nvalid = len(dataset_valid)*minibatch_size_valid\n",
    "logger.info(f'Nsample: {Nsample}, Nvalid: {Nvalid}.')\n",
    "logger.info(f'batch_size_train: {batch_size_train}, batch_size_valid: {batch_size_valid}')\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size_train // minibatch_size_train, shuffle=False)\n",
    "valid_loader = DataLoader(dataset_valid, batch_size=batch_size_valid // minibatch_size_valid, shuffle=False)\n",
    "\n",
    "model = GlasflowEmbdding(config).to(device)\n",
    "\n",
    "\n",
    "lr = config_training['lr']\n",
    "gamma = config_training['gamma']\n",
    "weight_decay = config_training['weight_decay']\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "logger.info(f'Initial learning rate: {lr}')\n",
    "logger.info(f'Gamma: {gamma}')\n",
    "\n",
    "max_epoch = config_training['max_epoch']\n",
    "#epoches_pretrain = config_training['epoches_pretrain']\n",
    "epoches_save_loss = config_training['epoches_save_loss']\n",
    "epoches_adjust_lr = config_training['epoches_adjust_lr']\n",
    "epoches_adjust_lr_again = config_training['epoches_adjust_lr_again']\n",
    "#load_from_previous_train = 1\n",
    "load_from_previous_train = config_training['load_from_previous_train']\n",
    "if load_from_previous_train:\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "\n",
    "    best_epoch = checkpoint['epoch']\n",
    "    start_epoch = best_epoch + 1\n",
    "    lr_updated_epoch = start_epoch\n",
    "    model.load_state_dict(checkpoint['model_state_dict']) \n",
    "\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "\n",
    "    train_losses = checkpoint['train_losses']\n",
    "    valid_losses = checkpoint['valid_losses']\n",
    "\n",
    "\n",
    "    logger.info(f'Loaded states from {ckpt_path}, epoch={start_epoch}.')\n",
    "else:\n",
    "    best_epoch = 0\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    start_epoch = 0\n",
    "    lr_updated_epoch = start_epoch\n",
    "\n",
    "npara_embd = count_parameters(model.embedding)\n",
    "npara_flow = count_parameters(model.flow)\n",
    "npara_total = count_parameters(model)\n",
    "logger.info(f'Learnable parameters: embedding: {npara_embd}, flow: {npara_flow}, total: {npara_total}. ')\n",
    "\n",
    "###\n",
    "#for g in optimizer.param_groups:\n",
    "#    g['lr'] = 1e-5\n",
    "#    logger.info(f'Set lr to 1e-5.')\n",
    "\n",
    "logger.info(f'Training started, device:{device}. ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "floating-series",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "composed-documentation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "speaking-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(start_epoch, 1):    \n",
    "\n",
    "    train_loss, train_loss_std = train_GlasNSFWarpper(model, optimizer, train_loader, device=device, minibatch_size=minibatch_size_train)\n",
    "    valid_loss, valid_loss_std = eval_GlasNSFWarpper(model, valid_loader, device=device, minibatch_size=minibatch_size_valid)\n",
    "\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    logger.info(f'epoch {epoch}, train loss = {train_loss}±{train_loss_std}, valid loss = {valid_loss}±{valid_loss_std}')\n",
    "\n",
    "    if valid_loss==min(valid_losses):\n",
    "        best_epoch = epoch\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_losses': train_losses,\n",
    "            'valid_losses': valid_losses,\n",
    "            }, ckpt_path)\n",
    "\n",
    "        logger.info(f'Current best epoch: {best_epoch}. Checkpoint saved.')\n",
    "\n",
    "    if epoch%epoches_save_loss == 0 and epoch!=0:\n",
    "        save_loss_data(train_losses, valid_losses, ckpt_dir)\n",
    "\n",
    "    if epoch-best_epoch>=epoches_adjust_lr and epoch-lr_updated_epoch>=epoches_adjust_lr_again:\n",
    "        adjust_lr(optimizer, gamma)\n",
    "        logger.info(f'Validation loss has not dropped for {epoch-best_epoch} epoches. Learning rate is decreased by a factor of {gamma}.')\n",
    "        lr_updated_epoch = epoch\n",
    "\n",
    "    #dataset_train.shuffle_indexinfile()\n",
    "    dataset_train.shuffle_wflist()\n",
    "    train_loader = DataLoader(dataset_train, batch_size=batch_size_train // minibatch_size_train, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "finnish-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "elementary-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "behind-moral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-circle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "awful-technical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.024776458740234"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "recovered-vienna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7709.6376953125"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "apart-drawing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134071248.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_loss_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "special-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, x in train_loader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "agreed-termination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10, 17])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sitting-proceeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10, 6, 3328])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "selected-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "minibatch_size = 10\n",
    "for theta, x in train_loader:\n",
    "    theta = theta.to(device)\n",
    "    x = x.to(device)\n",
    "\n",
    "    if minibatch_size>0:\n",
    "        # x: [bs, minibatch_size, nchannel, nbasis]\n",
    "        # theta: [bs, minibatch_size, npara]\n",
    "        bs = x.shape[0]\n",
    "        nbasis = x.shape[-1]\n",
    "        nchannel = x.shape[-2]\n",
    "        npara = theta.shape[-1]\n",
    "        theta = theta.view(bs*minibatch_size, npara)\n",
    "        x = x.view(bs*minibatch_size, nchannel, nbasis)\n",
    "    loss = -model.log_prob(theta, x).mean()\n",
    "\n",
    "    loss_list.append(loss.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "infrared-blond",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(7733.1514, device='cuda:0'), tensor(7739.5537, device='cuda:0')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "internal-crawford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 6, 3328])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "contemporary-birth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7739.5537, device='cuda:0', grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "logical-account",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 28 22:14:38 2024       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3080        Off |   00000000:01:00.0 Off |                  N/A |\r\n",
      "|  0%   16C    P8             15W /  320W |       3MiB /  10240MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   1  NVIDIA A100-PCIE-40GB          Off |   00000000:C1:00.0 Off |                    0 |\r\n",
      "| N/A   25C    P0             32W /  250W |   16920MiB /  40960MiB |      0%      Default |\r\n",
      "|                                         |                        |             Disabled |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|    1   N/A  N/A   2451206      C   python                                      12058MiB |\r\n",
      "|    1   N/A  N/A   3765180      C   .../.conda/envs/myigwn-py39/bin/python       4846MiB |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-charles",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
