{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hungry-holder",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/home/qian.hu/.conda/envs/myigwn-py39/lib/python3.9/site-packages/pycbc/types/array.py:36: UserWarning: Wswiglal-redir-stdio:\n",
      "\n",
      "SWIGLAL standard output/error redirection is enabled in IPython.\n",
      "This may lead to performance penalties. To disable locally, use:\n",
      "\n",
      "with lal.no_swig_redirect_standard_output_error():\n",
      "    ...\n",
      "\n",
      "To disable globally, use:\n",
      "\n",
      "lal.swig_redirect_standard_output_error(True)\n",
      "\n",
      "Note however that this will likely lead to error messages from\n",
      "LAL functions being either misdirected or lost when called from\n",
      "Jupyter notebooks.\n",
      "\n",
      "To suppress this warning, use:\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
      "import lal\n",
      "\n",
      "  import lal as _lal\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \"in-band\")\n",
    "\n",
    "import numpy as np\n",
    "import bilby \n",
    "import pycbc \n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import pickle\n",
    "#from sklearn.utils.extmath import randomized_svd\n",
    "import sklearn\n",
    "from sklearn.decomposition import IncrementalPCA, randomized_svd, KernelPCA\n",
    "import sklearn.decomposition \n",
    "\n",
    "import river.data\n",
    "from river.data.datagenerator import DataGeneratorBilbyFD\n",
    "from river.data.dataset import DatasetSVDStrainFDFromSVDWFonGPUBatch#DatasetStrainFD, #DatasetStrainFDFromPreCalSVDWF\n",
    "#import river.data.utils as datautils\n",
    "from river.data.utils import *\n",
    "from river.data.reparameterize import *\n",
    "\n",
    "from river.models import embedding\n",
    "from river.models.utils import *\n",
    "\n",
    "import sealgw\n",
    "import lal\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-minority",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "olive-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ifos = sealgw.simulation.sealinterferometers.SealInterferometerList(['H1', 'L1', 'V1', 'ET', 'CE','CEL'])\n",
    "ifos = bilby.gw.detector.InterferometerList(['H1', 'L1', 'V1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adverse-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "det = ifos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brilliant-flavor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3926141 , -0.07761341, -0.24738904],\n",
       "       [-0.07761341,  0.31952407,  0.22799783],\n",
       "       [-0.24738904,  0.22799783,  0.07309003]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det.geometry.detector_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "retained-knock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2161414.92636   , -3834695.17888835,  4600350.22663899])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det.vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "laden-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GWAntennaOnCPU():\n",
    "    def __init__(self, detector_names, gmst_fit = False, gps_start=None, gps_end=None):\n",
    "        self.ifos = sealgw.simulation.sealinterferometers.SealInterferometerList(detector_names)\n",
    "        self.gmst_fit = gmst_fit \n",
    "        if gmst_fit:\n",
    "            self.fit_linear_approx_gmst(gps_start, gps_end)\n",
    "\n",
    "    def fit_linear_approx_gmst(self, gps_start, gps_end):\n",
    "        t = np.linspace(gps_start, gps_end, 100000)\n",
    "        gmst=[]\n",
    "        for tt in t:\n",
    "            gmst.append(bilby.gw.utils.greenwich_mean_sidereal_time(tt))\n",
    "        gmst = np.array(gmst)\n",
    "        self.k, self.b = np.polyfit(t, gmst, 1)\n",
    "        self.gmst_fit = True\n",
    "\n",
    "        # validate the accuracy of linear fit \n",
    "        #t_test = np.linspace(gps_start, gps_end, 13417)\n",
    "        t_test = t\n",
    "        gmst_fit = self.k * t_test + self.b\n",
    "        #gmst_true = []\n",
    "        #for tt in t_test:\n",
    "        #    gmst_true.append(bilby.gw.utils.greenwich_mean_sidereal_time(tt))\n",
    "        #gmst_true = np.array(gmst_true)\n",
    "        gmst_true = gmst \n",
    "        err = np.max(np.abs(gmst_true - gmst_fit))\n",
    "        print(f\"Max error in linear fit of gmst: {err}\")\n",
    "        \n",
    "\n",
    "    def getgha(self, gpstime, ra):\n",
    "        # Greenwich hour angle of source (radians).\n",
    "        gha = np.zeros_like(gpstime) - ra\n",
    "\n",
    "        if self.gmst_fit:\n",
    "            gha += (self.k * gpstime + self.b)\n",
    "        else:\n",
    "            for i,gpst in enumerate(gpstime):\n",
    "                gha[i] += bilby.gw.utils.greenwich_mean_sidereal_time(gpst)\n",
    "        return gha\n",
    "    \n",
    "    def response(self, ra, dec, psi, gpstime):\n",
    "        bs = ra.shape[0]\n",
    "        \n",
    "        X = np.zeros((bs, 3))\n",
    "        Y = np.zeros((bs, 3))\n",
    "\n",
    "        \n",
    "        gha = self.getgha(gpstime, ra)\n",
    "\n",
    "        cosgha = np.cos(gha)\n",
    "        singha = np.sin(gha)\n",
    "        cosdec = np.cos(dec)\n",
    "        sindec = np.sin(dec)\n",
    "        cospsi = np.cos(psi)\n",
    "        sinpsi = np.sin(psi)\n",
    "    \n",
    "        X[:,0] = -cospsi * singha - sinpsi * cosgha * sindec\n",
    "        X[:,1] = -cospsi * cosgha + sinpsi * singha * sindec\n",
    "        X[:,2] =  sinpsi * cosdec\n",
    "\n",
    "        Y[:,0] =  sinpsi * singha - cospsi * cosgha * sindec\n",
    "        Y[:,1] =  sinpsi * cosgha + cospsi * singha * sindec\n",
    "        Y[:,2] =  cospsi * cosdec\n",
    "        \n",
    "        resp_dict = {}\n",
    "        for det in self.ifos:\n",
    "            D = det.detector_tensor\n",
    "            fp = np.einsum('ij,jk,ik->i', X, D, X) - np.einsum('ij,jk,ik->i', Y, D, Y)\n",
    "            fc = np.einsum('ij,jk,ik->i', X, D, Y) + np.einsum('ij,jk,ik->i', Y, D, X)\n",
    "            resp_dict[det.name] = (fp, fc)\n",
    "\n",
    "        return resp_dict\n",
    "    \n",
    "    def time_delay_from_geocenter(self, ra, dec, gpstime):\n",
    "        bs = ra.shape[0]\n",
    "        gha = self.getgha(gpstime, ra)\n",
    "        \n",
    "        cosgha = np.cos(gha)\n",
    "        singha = np.sin(gha)\n",
    "        cosdec = np.cos(dec)\n",
    "        sindec = np.sin(dec)\n",
    "        \n",
    "        wavevector = np.zeros((bs, 3))\n",
    "        wavevector[:,0],wavevector[:,1],wavevector[:,2]  = \\\n",
    "            -cosgha*cosdec, cosdec*singha, -sindec\n",
    "        \n",
    "        dt_dict = {}\n",
    "        for det in self.ifos:\n",
    "            loc = det.vertex\n",
    "            dt = np.einsum('ij,j->i', wavevector, loc) / 299792458\n",
    "            dt_dict[det.name] = dt\n",
    "        \n",
    "        return dt_dict\n",
    "\n",
    "    def resp_and_dt(self, ra, dec, gpstime, psi):\n",
    "        bs = ra.shape[0]        \n",
    "        X = np.zeros((bs, 3))\n",
    "        Y = np.zeros((bs, 3))\n",
    "\n",
    "        gha = self.getgha(gpstime, ra)\n",
    "\n",
    "        cosgha = np.cos(gha)\n",
    "        singha = np.sin(gha)\n",
    "        cosdec = np.cos(dec)\n",
    "        sindec = np.sin(dec)\n",
    "        cospsi = np.cos(psi)\n",
    "        sinpsi = np.sin(psi)\n",
    "        \n",
    "        X[:,0] = -cospsi * singha - sinpsi * cosgha * sindec\n",
    "        X[:,1] = -cospsi * cosgha + sinpsi * singha * sindec\n",
    "        X[:,2] =  sinpsi * cosdec\n",
    "\n",
    "        Y[:,0] =  sinpsi * singha - cospsi * cosgha * sindec\n",
    "        Y[:,1] =  sinpsi * cosgha + cospsi * singha * sindec\n",
    "        Y[:,2] =  cospsi * cosdec\n",
    "\n",
    "        \n",
    "        \n",
    "        wavevector = np.zeros((bs, 3))\n",
    "        wavevector[:,0],wavevector[:,1],wavevector[:,2]  = \\\n",
    "            -cosgha*cosdec, cosdec*singha, -sindec\n",
    "        \n",
    "        resp_and_dt_dict = {}\n",
    "        for det in self.ifos:\n",
    "            loc = det.vertex\n",
    "            D = det.detector_tensor\n",
    "            \n",
    "            fp = np.einsum('ij,jk,ik->i', X, D, X) - np.einsum('ij,jk,ik->i', Y, D, Y)\n",
    "            fc = np.einsum('ij,jk,ik->i', X, D, Y) + np.einsum('ij,jk,ik->i', Y, D, X)\n",
    "            dt = np.einsum('ij,j->i', wavevector, loc) / 299792458\n",
    "            resp_and_dt_dict[det.name] = [fp,fc,dt]\n",
    "\n",
    "        return resp_and_dt_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GWAntennaOnGPU():\n",
    "    def __init__(self, detector_names, gmst_fit=False, gps_start=None, gps_end=None, device='cuda', dtype=torch.float64):\n",
    "        self.ifos = sealgw.simulation.sealinterferometers.SealInterferometerList(detector_names)\n",
    "        self.gmst_fit = gmst_fit\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        if gmst_fit:\n",
    "            self.fit_linear_approx_gmst(gps_start, gps_end)\n",
    "\n",
    "    def fit_linear_approx_gmst(self, gps_start, gps_end):\n",
    "        t = np.linspace(gps_start, gps_end, 100000).astype(np.float64)\n",
    "        gmst = []\n",
    "        for tt in t:\n",
    "            gmst.append(bilby.gw.utils.greenwich_mean_sidereal_time(tt))\n",
    "        gmst = np.array(gmst)\n",
    "        self.k, self.b = np.polyfit(t, gmst, 1)\n",
    "        self.gmst_fit = True\n",
    "\n",
    "        # validate the accuracy of linear fit\n",
    "        t_test = t\n",
    "        gmst_fit = self.k * t_test + self.b\n",
    "        gmst_true = gmst\n",
    "        err = np.max(np.abs(gmst_true - gmst_fit))\n",
    "        print(f\"Max error in linear fit of gmst: {err}\")\n",
    "        \n",
    "        self.k = torch.tensor(self.k).to(self.device).type(self.dtype)\n",
    "        self.b = torch.tensor(self.b).to(self.device).type(self.dtype)\n",
    "\n",
    "    def getgha(self, gpstime, ra):\n",
    "        # Greenwich hour angle of source (radians).\n",
    "        gha = torch.zeros_like(gpstime, device=self.device, dtype=self.dtype) - ra\n",
    "\n",
    "        if self.gmst_fit:\n",
    "            gha += (self.k * gpstime + self.b)\n",
    "        else:\n",
    "            for i, gpst in enumerate(gpstime):\n",
    "                gha[i] += bilby.gw.utils.greenwich_mean_sidereal_time(gpst)\n",
    "        return gha\n",
    "\n",
    "    def response(self, ra, dec, psi, gpstime):\n",
    "        bs = ra.shape[0]\n",
    "\n",
    "        X = torch.zeros((bs, 3), device=self.device, dtype=self.dtype)\n",
    "        Y = torch.zeros((bs, 3), device=self.device, dtype=self.dtype)\n",
    "\n",
    "        gha = self.getgha(gpstime, ra)\n",
    "\n",
    "        cosgha = torch.cos(gha)\n",
    "        singha = torch.sin(gha)\n",
    "        cosdec = torch.cos(dec)\n",
    "        sindec = torch.sin(dec)\n",
    "        cospsi = torch.cos(psi)\n",
    "        sinpsi = torch.sin(psi)\n",
    "\n",
    "        X[:, 0] = -cospsi * singha - sinpsi * cosgha * sindec\n",
    "        X[:, 1] = -cospsi * cosgha + sinpsi * singha * sindec\n",
    "        X[:, 2] = sinpsi * cosdec\n",
    "\n",
    "        Y[:, 0] = sinpsi * singha - cospsi * cosgha * sindec\n",
    "        Y[:, 1] = sinpsi * cosgha + cospsi * singha * sindec\n",
    "        Y[:, 2] = cospsi * cosdec\n",
    "\n",
    "        resp_dict = {}\n",
    "        for det in self.ifos:\n",
    "            D = torch.from_numpy(det.detector_tensor).to(self.device).type(self.dtype)\n",
    "            fp = torch.einsum('ij,jk,ik->i', X, D, X) - torch.einsum('ij,jk,ik->i', Y, D, Y)\n",
    "            fc = torch.einsum('ij,jk,ik->i', X, D, Y) + torch.einsum('ij,jk,ik->i', Y, D, X)\n",
    "            resp_dict[det.name] = (fp, fc)\n",
    "\n",
    "        return resp_dict\n",
    "\n",
    "    def time_delay_from_geocenter(self, ra, dec, gpstime):\n",
    "        bs = ra.shape[0]\n",
    "        gha = self.getgha(gpstime, ra)\n",
    "\n",
    "        cosgha = torch.cos(gha)\n",
    "        singha = torch.sin(gha)\n",
    "        cosdec = torch.cos(dec)\n",
    "        sindec = torch.sin(dec)\n",
    "\n",
    "        wavevector = torch.zeros((bs, 3), device=self.device, dtype=self.dtype)\n",
    "        wavevector[:, 0], wavevector[:, 1], wavevector[:, 2] = \\\n",
    "            -cosgha * cosdec, cosdec * singha, -sindec\n",
    "\n",
    "        dt_dict = {}\n",
    "        for det in self.ifos:\n",
    "            loc = torch.from_numpy(det.vertex).to(self.device).type(self.dtype)\n",
    "            dt = torch.einsum('ij,j->i', wavevector, loc) / 299792458\n",
    "            dt_dict[det.name] = dt\n",
    "\n",
    "        return dt_dict\n",
    "\n",
    "    def resp_and_dt(self, ra, dec, gpstime, psi):\n",
    "        bs = ra.shape[0]\n",
    "        X = torch.zeros((bs, 3), device=self.device, dtype=self.dtype)\n",
    "        Y = torch.zeros((bs, 3), device=self.device, dtype=self.dtype)\n",
    "\n",
    "        gha = self.getgha(gpstime, ra)\n",
    "\n",
    "        cosgha = torch.cos(gha)\n",
    "        singha = torch.sin(gha)\n",
    "        cosdec = torch.cos(dec)\n",
    "        sindec = torch.sin(dec)\n",
    "        cospsi = torch.cos(psi)\n",
    "        sinpsi = torch.sin(psi)\n",
    "\n",
    "        X[:, 0] = -cospsi * singha - sinpsi * cosgha * sindec\n",
    "        X[:, 1] = -cospsi * cosgha + sinpsi * singha * sindec\n",
    "        X[:, 2] = sinpsi * cosdec\n",
    "\n",
    "        Y[:, 0] = sinpsi * singha - cospsi * cosgha * sindec\n",
    "        Y[:, 1] = sinpsi * cosgha + cospsi * singha * sindec\n",
    "        Y[:, 2] = cospsi * cosdec\n",
    "\n",
    "        wavevector = torch.zeros((bs, 3), device=self.device, dtype=self.dtype)\n",
    "        wavevector[:, 0], wavevector[:, 1], wavevector[:, 2] = \\\n",
    "            -cosgha * cosdec, cosdec * singha, -sindec\n",
    "\n",
    "\n",
    "        wavevector = wavevector.detach()\n",
    "        resp_and_dt_dict = {}\n",
    "        for det in self.ifos:\n",
    "            loc = torch.from_numpy(det.vertex).to(self.device).type(self.dtype)\n",
    "            D = torch.from_numpy(det.detector_tensor).to(self.device).type(self.dtype)\n",
    "            \n",
    "            fp = torch.einsum('ij,jk,ik->i', X, D, X) - torch.einsum('ij,jk,ik->i', Y, D, Y)\n",
    "            fc = torch.einsum('ij,jk,ik->i', X, D, Y) + torch.einsum('ij,jk,ik->i', Y, D, X)\n",
    "            dt = torch.einsum('ij,j->i', wavevector, loc) / 299792458.0\n",
    "            resp_and_dt_dict[det.name] = [fp, fc, dt]\n",
    "\n",
    "\n",
    "        return resp_and_dt_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "induced-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GWAntennaOnGPU2():\n",
    "    def __init__(self, detector_names, gmst_fit=False, gps_start=None, gps_end=None, device='cuda', dtype=torch.float64):\n",
    "        self.ifos = sealgw.simulation.sealinterferometers.SealInterferometerList(detector_names)\n",
    "        self.gmst_fit = gmst_fit\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        if gmst_fit:\n",
    "            self.fit_linear_approx_gmst(gps_start, gps_end)\n",
    "        self.locs = torch.stack([torch.from_numpy(det.vertex).to(self.device).type(self.dtype) for det in self.ifos])\n",
    "        self.Ds = torch.stack([torch.from_numpy(det.detector_tensor).to(self.device).type(self.dtype) for det in self.ifos])\n",
    "\n",
    "    def fit_linear_approx_gmst(self, gps_start, gps_end):\n",
    "        t = np.linspace(gps_start, gps_end, 100000).astype(np.float64)\n",
    "        gmst = []\n",
    "        for tt in t:\n",
    "            gmst.append(bilby.gw.utils.greenwich_mean_sidereal_time(tt))\n",
    "        gmst = np.array(gmst)\n",
    "        self.k, self.b = np.polyfit(t, gmst, 1)\n",
    "        self.gmst_fit = True\n",
    "\n",
    "        # validate the accuracy of linear fit\n",
    "        t_test = t\n",
    "        gmst_fit = self.k * t_test + self.b\n",
    "        gmst_true = gmst\n",
    "        err = np.max(np.abs(gmst_true - gmst_fit))\n",
    "        print(f\"Max error in linear fit of gmst: {err}\")\n",
    "        \n",
    "        self.k = torch.tensor(self.k).to(self.device).type(self.dtype)\n",
    "        self.b = torch.tensor(self.b).to(self.device).type(self.dtype)\n",
    "\n",
    "    def getgha(self, gpstime, ra):\n",
    "        # Greenwich hour angle of source (radians).\n",
    "        gha = torch.zeros_like(gpstime, device=self.device, dtype=self.dtype) - ra\n",
    "\n",
    "        if self.gmst_fit:\n",
    "            gha += (self.k * gpstime + self.b)\n",
    "        else:\n",
    "            for i, gpst in enumerate(gpstime):\n",
    "                gha[i] += bilby.gw.utils.greenwich_mean_sidereal_time(gpst)\n",
    "        return gha\n",
    "\n",
    "    def resp_and_dt(self, ra, dec, gpstime, psi):\n",
    "        bs = ra.shape[0]\n",
    "        X = torch.zeros((bs, 3), device=self.device, dtype=self.dtype)\n",
    "        Y = torch.zeros((bs, 3), device=self.device, dtype=self.dtype)\n",
    "\n",
    "        gha = self.getgha(gpstime, ra)\n",
    "\n",
    "        cosgha = torch.cos(gha)\n",
    "        singha = torch.sin(gha)\n",
    "        cosdec = torch.cos(dec)\n",
    "        sindec = torch.sin(dec)\n",
    "        cospsi = torch.cos(psi)\n",
    "        sinpsi = torch.sin(psi)\n",
    "\n",
    "        X[:, 0] = -cospsi * singha - sinpsi * cosgha * sindec\n",
    "        X[:, 1] = -cospsi * cosgha + sinpsi * singha * sindec\n",
    "        X[:, 2] = sinpsi * cosdec\n",
    "\n",
    "        Y[:, 0] = sinpsi * singha - cospsi * cosgha * sindec\n",
    "        Y[:, 1] = sinpsi * cosgha + cospsi * singha * sindec\n",
    "        Y[:, 2] = cospsi * cosdec\n",
    "\n",
    "        wavevector = torch.zeros((bs, 3), device=self.device, dtype=self.dtype)\n",
    "        wavevector[:, 0], wavevector[:, 1], wavevector[:, 2] = \\\n",
    "            -cosgha * cosdec, cosdec * singha, -sindec\n",
    "\n",
    "        wavevector = wavevector.detach()\n",
    "\n",
    "        fps = torch.einsum('ij,ajk,ik->ia', X, self.Ds, X) - torch.einsum('ij,ajk,ik->ia', Y, self.Ds, Y)\n",
    "        fcs = torch.einsum('ij,ajk,ik->ia', X, self.Ds, Y) + torch.einsum('ij,ajk,ik->ia', Y, self.Ds, X)\n",
    "        dts = torch.einsum('ij,aj->ia', wavevector, self.locs) / 299792458.0\n",
    "\n",
    "        resp_and_dt_dict = {det.name: [fp, fc, dt] for det, fp, fc, dt in zip(self.ifos, fps.T, fcs.T, dts.T)}\n",
    "\n",
    "        return resp_and_dt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "affecting-vermont",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max error in linear fit of gmst: 1.4915713109076023e-09\n",
      "Max error in linear fit of gmst: 1.4915713109076023e-09\n",
      "Max error in linear fit of gmst: 1.4915713109076023e-09\n"
     ]
    }
   ],
   "source": [
    "detnames = ['H1', 'L1', 'V1', 'ET', 'CE','CEL']\n",
    "device = 'cuda'\n",
    "at_cpu = GWAntennaOnCPU(detector_names=detnames)\n",
    "at_cpu_approx = GWAntennaOnCPU(detector_names=detnames, gmst_fit=True, gps_start=0, gps_end=40000)\n",
    "at_gpu_approx = GWAntennaOnGPU(detector_names=detnames, gmst_fit=True, gps_start=0, gps_end=40000,\n",
    "                              device=device, dtype=torch.float64)\n",
    "at_gpu_approx2 = GWAntennaOnGPU2(detector_names=detnames, gmst_fit=True, gps_start=0, gps_end=40000,\n",
    "                              device=device, dtype=torch.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-sperm",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "loose-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntest  = 1024*6000\n",
    "#Ntest  = 100\n",
    "\n",
    "test_ra = np.linspace(0,2,Ntest)\n",
    "test_dec = np.linspace(-1.5,1.5,Ntest)\n",
    "test_psi = np.linspace(0,3,Ntest)\n",
    "test_tc = np.linspace(0,30000,Ntest)\n",
    "\n",
    "test_ra_gpu = torch.from_numpy(test_ra).to(device)\n",
    "test_dec_gpu = torch.from_numpy(test_dec).to(device)\n",
    "test_psi_gpu = torch.from_numpy(test_psi).to(device)\n",
    "test_tc_gpu = torch.from_numpy(test_tc).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acute-search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.33176851272583\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "resp_and_dt_dict_cpu = at_cpu.resp_and_dt(test_ra, test_dec, test_psi, test_tc)\n",
    "t2 = time.time()\n",
    "\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adapted-highway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.31053829193115\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "resp_and_dt_dict_cpu_approx = at_cpu_approx.resp_and_dt(test_ra, test_dec, test_psi, test_tc)\n",
    "t2 = time.time()\n",
    "\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "lyric-territory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5746316909790039\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "resp_and_dt_dict_gpu_approx = at_gpu_approx.resp_and_dt(test_ra_gpu, test_dec_gpu, test_psi_gpu, test_tc_gpu)\n",
    "t2 = time.time()\n",
    "\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "selected-worcester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006478548049926758\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "resp_and_dt_dict_gpu_approx2 = at_gpu_approx2.resp_and_dt(test_ra_gpu, test_dec_gpu, test_psi_gpu, test_tc_gpu)\n",
    "t2 = time.time()\n",
    "\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "static-danish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6555820603336713e-09\n",
      "1.2181918251918944e-09\n",
      "1.653243986154962e-09\n",
      "1.1267644040025004e-09\n",
      "1.5250927326571073e-09\n",
      "1.3846087054680822e-09\n",
      "1.6556176429816105e-09\n",
      "1.2181918251918944e-09\n"
     ]
    }
   ],
   "source": [
    "for detname in resp_and_dt_dict_cpu_approx.keys():\n",
    "    error = np.array(resp_and_dt_dict_cpu_approx[detname]) - np.array(resp_and_dt_dict_cpu[detname])\n",
    "    print(np.max(abs(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "periodic-ethics",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-180-638f8968bb8d>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gpu_result = np.array(torch.tensor(resp_and_dt_dict_gpu_approx[detname][i]).cpu().type(torch.float32))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9802232681674923e-08\n",
      "2.9802294743142e-08\n",
      "4.656612699605045e-10\n",
      "2.980231328386651e-08\n",
      "2.9802320167249263e-08\n",
      "4.656609819964075e-10\n",
      "2.980231139648737e-08\n",
      "2.980229618643193e-08\n",
      "9.313224115514718e-10\n",
      "2.9802305290260733e-08\n",
      "2.9802303069814684e-08\n",
      "9.313224115514718e-10\n",
      "2.9802306844572968e-08\n",
      "2.9802282419666426e-08\n",
      "9.313220576678827e-10\n",
      "2.9802309731152832e-08\n",
      "2.9802305290260733e-08\n",
      "9.313225642071377e-10\n",
      "2.9802319390093146e-08\n",
      "2.9802320611338473e-08\n",
      "4.656612699605045e-10\n",
      "2.980231328386651e-08\n",
      "2.9802320167249263e-08\n",
      "4.656609819964075e-10\n"
     ]
    }
   ],
   "source": [
    "for detname in resp_and_dt_dict_cpu_approx.keys():\n",
    "    for i in range(3):\n",
    "        gpu_result = np.array(torch.tensor(resp_and_dt_dict_gpu_approx[detname][i]).cpu())\n",
    "        cpu_result = resp_and_dt_dict_cpu_approx[detname][i]\n",
    "        error = np.array(cpu_result) - np.array(gpu_result)\n",
    "        print(np.max(abs(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "seventh-pixel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-74cf5f536045>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gpu_result = np.array(torch.tensor(resp_and_dt_dict_gpu_approx2[detname][i]).cpu())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.551115123125783e-16\n",
      "6.661338147750939e-16\n",
      "6.938893903907228e-18\n",
      "5.551115123125783e-16\n",
      "6.661338147750939e-16\n",
      "8.673617379884035e-18\n",
      "6.661338147750939e-16\n",
      "7.771561172376096e-16\n",
      "6.938893903907228e-18\n",
      "6.661338147750939e-16\n",
      "6.661338147750939e-16\n",
      "6.938893903907228e-18\n",
      "6.661338147750939e-16\n",
      "6.661338147750939e-16\n",
      "1.0408340855860843e-17\n",
      "6.661338147750939e-16\n",
      "5.551115123125783e-16\n",
      "1.0408340855860843e-17\n",
      "5.551115123125783e-16\n",
      "6.661338147750939e-16\n",
      "6.938893903907228e-18\n",
      "5.551115123125783e-16\n",
      "6.661338147750939e-16\n",
      "8.673617379884035e-18\n"
     ]
    }
   ],
   "source": [
    "for detname in resp_and_dt_dict_cpu_approx.keys():\n",
    "    for i in range(3):\n",
    "        gpu_result = np.array(torch.tensor(resp_and_dt_dict_gpu_approx2[detname][i]).cpu())\n",
    "        cpu_result = resp_and_dt_dict_cpu_approx[detname][i]\n",
    "        error = np.array(cpu_result) - np.array(gpu_result)\n",
    "        print(np.max(abs(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-magnet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-ceiling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "opponent-identity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.634796857833862\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "resp_and_dt_dict_real = {}\n",
    "\n",
    "for det in tt.ifos:\n",
    "    fp_real = []\n",
    "    fc_real = []\n",
    "    dt_real = []\n",
    "\n",
    "    for i in range(Ntest):\n",
    "        fp_real.append(det.antenna_response(test_ra[i], test_dec[i], test_tc[i], test_psi[i], 'plus'))\n",
    "        fc_real.append(det.antenna_response(test_ra[i], test_dec[i], test_tc[i], test_psi[i], 'cross'))\n",
    "        dt_real.append(det.time_delay_from_geocenter(test_ra[i], test_dec[i], test_tc[i]))\n",
    "\n",
    "    fp_real = np.array(fp_real)\n",
    "    fc_real = np.array(fc_real)\n",
    "    dt_real = np.array(dt_real)\n",
    "\n",
    "    resp_and_dt_dict_real[det.name] = (fp_real, fc_real, dt_real)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-venice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "beginning-government",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1\n",
      "L1\n",
      "V1\n",
      "ET1\n",
      "ET2\n",
      "0.0016637406934446874\n"
     ]
    }
   ],
   "source": [
    "maxerror = 0\n",
    "for det in tt.ifos:\n",
    "    detname1 = det.name\n",
    "    ##if detname1=='ET1':\n",
    "    #    detname2 = 'ET2'\n",
    "    #elif detname1=='ET2':\n",
    "    #    detname2 = 'ET1'\n",
    "    #else:\n",
    "    #    detname2 = detname1\n",
    "    tempmax = np.max(np.array(resp_and_dt_dict_real[detname1]) - np.array(resp_and_dt_dict[detname1]) )\n",
    "    if maxerror<tempmax:\n",
    "        print(det.name)\n",
    "        maxerror = tempmax\n",
    "        \n",
    "print(maxerror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-latex",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dominant-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "validfolder = '/home/qian.hu/mlpe/training_data/bns_50Hz1024Hz32s_lowspin_lb/valid'\n",
    "trainfolder = '/home/qian.hu/mlpe/training_data/bns_50Hz1024Hz32s_lowspin_lb/train'\n",
    "#noisefolder = '/home/qian.hu/mlpe/training_data/bns_50Hz1024Hz32s_lowspin/noise/design'\n",
    "\n",
    "valid_filenames = glob.glob(f\"{validfolder}/batch*/*.h5\")\n",
    "train_filenames = glob.glob(f\"{trainfolder}/batch*/*.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-bahrain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "duplicate-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadVandVh(Vhfilepath, Nbasis):\n",
    "    with open(Vhfilepath, 'rb') as f:\n",
    "        Vh = pickle.load(f)\n",
    "    if len(Vh)<Nbasis:\n",
    "        raise ValueError(f'required Nbasis ({Nbasis}) > len(Vh) ({len(Vh)})!')\n",
    "    Vh = Vh[:Nbasis]\n",
    "    V = Vh.T.conj()\n",
    "        \n",
    "    return V, Vh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "economic-swiss",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:28 bilby INFO    : Waveform generator initiated with\n",
      "  frequency_domain_source_model: bilby.gw.source.lal_binary_neutron_star\n",
      "  time_domain_source_model: None\n",
      "  parameter_conversion: bilby.gw.conversion.convert_to_lal_binary_black_hole_parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bilby_default PSDs to generate data.\n"
     ]
    }
   ],
   "source": [
    "source_type = 'BNS'\n",
    "detector_names = ['H1', 'L1', 'V1'] \n",
    "duration = 32\n",
    "f_low = 50\n",
    "f_high = 1024\n",
    "\n",
    "f_ref = 20\n",
    "sampling_frequency = 2048\n",
    "waveform_approximant = 'IMRPhenomPv2_NRTidal'\n",
    "parameter_names = PARAMETER_NAMES_ALL_PRECESSINGBNS_BILBY\n",
    "PSD_type = 'bilby_default' #'zero_noise' bilby_default\n",
    "use_sealgw_detector = True\n",
    "\n",
    "Vhfile=\"/home/qian.hu/mlpe/river/test/outputs/Vh_50Hz1024Hz32s.pickle\"\n",
    "\n",
    "data_generator = DataGeneratorBilbyFD(source_type,\n",
    "            detector_names, \n",
    "            duration, \n",
    "            f_low, \n",
    "            f_ref, \n",
    "            sampling_frequency, \n",
    "            waveform_approximant, \n",
    "            parameter_names,\n",
    "            PSD_type=PSD_type,\n",
    "            use_sealgw_detector=use_sealgw_detector,\n",
    "            f_high=f_high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "average-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSVDStrainFDFromSVDWFonGPUBatchNew(Dataset):\n",
    "    '''\n",
    "    Simulate FD data in SVD space from pre-calculated SVD waveforms, optimized for GPU or CPU computation.\n",
    "\n",
    "    Load a batch of data, i.e. return [minibatch_size, dim1, dim2, ...]. The batch size should be 2^N. \n",
    "    '''\n",
    "    def __init__(self, precalwf_filelist, parameter_names, data_generator, Nbasis, Vhfile,\n",
    "                dmin=10, dmax=200, dpower=1, device='cuda',\n",
    "                add_noise=True, minibatch_size=1, fix_extrinsic=False, shuffle=True, reparameterize=True):\n",
    "        self.precalwf_filelist = precalwf_filelist\n",
    "        self.parameter_names = parameter_names\n",
    "        self.data_generator = data_generator\n",
    "        self.Nbasis = Nbasis\n",
    "        self.dmin = dmin\n",
    "        self.dmax = dmax\n",
    "        self.dpower = dpower\n",
    "        self.device = device\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.add_noise = add_noise\n",
    "        self.fix_extrinsic = fix_extrinsic\n",
    "        self.shuffle = shuffle\n",
    "        self.reparameterize = reparameterize\n",
    "\n",
    "        # Load V and Vh matrices and convert to tensors\n",
    "        self.V, self.Vh = loadVandVh(Vhfile, Nbasis)\n",
    "        self.V = torch.from_numpy(self.V).to(self.device).type(torch.complex64)\n",
    "        self.Vh = torch.from_numpy(self.Vh).to(self.device).type(torch.complex64)\n",
    "\n",
    "        self.antenna = GWAntennaOnCPU(data_generator.detector_names)\n",
    "        self.farray = torch.from_numpy(data_generator.frequency_array_masked).float().to(self.device)\n",
    "        self.ifos = data_generator.ifos\n",
    "        self.det_data = self.prepare_detector_data()\n",
    "        \n",
    "        testfile = load_dict_from_hdf5(precalwf_filelist[0])\n",
    "        self.sample_per_file = len(testfile['injection_parameters']['chirp_mass'])\n",
    "        #if self.sample_per_file<self.minibatch_size:\n",
    "        #    raise ValueError(\"Sample per file < batch size!\")\n",
    "        self.Nfile = len(self.precalwf_filelist)\n",
    "        self.Nsample = self.Nfile * self.sample_per_file \n",
    "        self.cached_wf_file = testfile\n",
    "        self.cached_wf_file_index = 0\n",
    "            \n",
    "        self.shuffle_indexinfile()\n",
    "        \n",
    "        assert self.sample_per_file % self.minibatch_size == 0\n",
    "        \n",
    "    def prepare_detector_data(self):\n",
    "        det_data = {}\n",
    "        for det in self.ifos:\n",
    "            detname = det.name\n",
    "            psd = det.power_spectral_density_array[self.data_generator.frequency_mask]\n",
    "            psd = torch.from_numpy(psd).double().to(self.device)\n",
    "            whitened_V = (self.V.T * 1/(psd*det.duration/4)**0.5).T\n",
    "            det_data[detname] = {'whitened_V': whitened_V.type(torch.complex64)}\n",
    "        return det_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.precalwf_filelist) * self.sample_per_file // self.minibatch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index >= len(self):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        \n",
    "        \n",
    "        index = index*self.minibatch_size\n",
    "        index_end = index + self.minibatch_size\n",
    "        index_of_file, index_in_file = self.get_index(index, self.sample_per_file)\n",
    "        index_of_file_end, index_in_file_end = self.get_index(index_end, self.sample_per_file, is_end=True)\n",
    "        \n",
    "        assert index_of_file == index_of_file_end\n",
    "        assert index_of_file < len(self.precalwf_filelist)\n",
    "\n",
    "        \n",
    "        wf_dict = self.get_precalwf_dict(index_of_file)\n",
    "        hp_svd, hc_svd, injection_parameters = self.get_waveform_tensors_batch(wf_dict, index_in_file, index_in_file_end)\n",
    "        injection_parameters = self.update_injection_parameters_batch(injection_parameters)\n",
    "        \n",
    "        dL = torch.from_numpy(injection_parameters['luminosity_distance']).to(self.device).unsqueeze(-1)\n",
    "        hp_svd = hp_svd/dL\n",
    "        hc_svd = hc_svd/dL\n",
    "\n",
    "        x = self.compute_strain_tensors_batch(hp_svd, hc_svd, injection_parameters)\n",
    "        theta = self.get_theta(injection_parameters)\n",
    "        return theta, torch.cat((x.real, x.imag), axis=1).float()\n",
    "\n",
    "    def get_index(self, index, sample_per_file, is_end=False):\n",
    "        index_of_file = index // sample_per_file\n",
    "        index_in_file = index - index_of_file*sample_per_file\n",
    "        \n",
    "        if is_end and index_in_file==0:\n",
    "            index_in_file = None\n",
    "            index_of_file -= 1\n",
    "        return index_of_file, index_in_file\n",
    "    \n",
    "    \n",
    "    def get_precalwf_dict(self, index_of_file):\n",
    "        if self.cached_wf_file_index == index_of_file:\n",
    "            return self.cached_wf_file\n",
    "        else:\n",
    "            try:\n",
    "                wf_dict = load_dict_from_hdf5(self.precalwf_filelist[index_of_file])\n",
    "            except:\n",
    "                raise Exception(f'index_of_file: {index_of_file}')\n",
    "            self.cached_wf_file = wf_dict\n",
    "            self.cached_wf_file_index = index_of_file\n",
    "            return wf_dict\n",
    "    \n",
    "    \n",
    "    def get_waveform_tensors_batch(self, wf_dict, index_in_file, index_in_file_end):\n",
    "\n",
    "        \n",
    "        index = self.random_index_in_file[index_in_file:index_in_file_end]\n",
    "        hp_svd = (torch.from_numpy(wf_dict['waveform_polarizations']['plus'][index])).type(torch.complex64).to(self.device)\n",
    "        hc_svd = (torch.from_numpy(wf_dict['waveform_polarizations']['cross'][index])).type(torch.complex64).to(self.device)\n",
    "        \n",
    "        para_name_list = ['chirp_mass', 'mass_ratio', 'a_1', 'a_2', 'tilt_1', 'tilt_2', 'phi_12', 'phi_jl',\n",
    "                    'lambda_tilde', 'delta_lambda_tilde', 'theta_jn', 'phase']\n",
    "        injection_parameters = injection_parameters = {key: wf_dict['injection_parameters'][key][index] for key in para_name_list}\n",
    "        \n",
    "        # last wf in this file\n",
    "        if (index_in_file_end is None) and (self.cached_wf_file_index < len(self.precalwf_filelist)-1): \n",
    "            _ = self.get_precalwf_dict(self.cached_wf_file_index + 1)\n",
    "            print('Automatically updated cached wf.')\n",
    "\n",
    "        return hp_svd, hc_svd, injection_parameters\n",
    "\n",
    "    def get_noise_tensors_batch(self, ):\n",
    "        white_noise = (torch.randn((self.minibatch_size, self.Nbasis), device=self.device) + \\\n",
    "                       1j * torch.randn((self.minibatch_size, self.Nbasis), device=self.device)).type(torch.complex64)\n",
    "\n",
    "        return white_noise\n",
    "    \n",
    "    def compute_strain_tensors_batch(self, hp_svd, hc_svd, injection_parameters):\n",
    "        num_ifos = len(self.ifos)\n",
    "        x = torch.zeros((self.minibatch_size, num_ifos, self.Nbasis), dtype=torch.complex64, device=self.device)\n",
    "        resp_dt_dict = self.compute_detector_factors_batch(injection_parameters)\n",
    "        for i,det in enumerate(self.ifos):\n",
    "            detname = det.name\n",
    "\n",
    "            fp, fc, dt = resp_dt_dict[detname]\n",
    "            fp = torch.from_numpy(fp).to(self.device).unsqueeze(1)\n",
    "            fc = torch.from_numpy(fc).to(self.device).unsqueeze(1)\n",
    "            dt = torch.from_numpy(dt).to(self.device).unsqueeze(1)\n",
    "\n",
    "            phase2add = torch.exp(-1j * 2 * np.pi * dt * self.farray).type(torch.complex64)\n",
    "            Vh_recons = self.Vh\n",
    "            hh = (fp*hp_svd + fc*hc_svd).type(torch.complex64)\n",
    "\n",
    "            hh_reconstruct = torch.einsum('ij,jk->ik', hh, Vh_recons)\n",
    "\n",
    "            hh_shifted = hh_reconstruct * phase2add\n",
    "            h_svd = torch.einsum('ij,jk->ik', hh_shifted, self.det_data[detname]['whitened_V'])\n",
    "\n",
    "            if self.add_noise:\n",
    "                n_svd = self.get_noise_tensors_batch()\n",
    "                d_svd = h_svd + n_svd\n",
    "            else:\n",
    "                d_svd = h_svd\n",
    "\n",
    "            x[:,i,:] = d_svd\n",
    "            \n",
    "\n",
    "        return x\n",
    "    \n",
    "    def compute_detector_factors_batch(self, injection_parameters):\n",
    "\n",
    "        ra = injection_parameters['ra']\n",
    "        dec = injection_parameters['dec']\n",
    "        tc = injection_parameters['geocent_time']\n",
    "        psi = injection_parameters['psi']\n",
    "\n",
    "        resp_dt_dict = self.antenna.resp_and_dt(ra,dec,tc,psi)    \n",
    "        dt_geocent = tc  #- self.strain_data.start_time\n",
    "        for key,value in resp_dt_dict.items():\n",
    "            value[2] += dt_geocent        \n",
    "\n",
    "        return resp_dt_dict\n",
    "    \n",
    "    '''\n",
    "    def get_theta(self, injection_parameters):\n",
    "        if self.fix_extrinsic:\n",
    "            reduced_parameter_names = ['chirp_mass', 'mass_ratio', 'a_1', 'a_2', 'tilt_1', 'tilt_2', 'phi_12', 'phi_jl',\n",
    "                    'lambda_tilde', 'delta_lambda_tilde', 'theta_jn', 'phase']\n",
    "            theta = torch.tensor(np.array([injection_parameters[paraname] for paraname in reduced_parameter_names]), dtype=torch.float32).to(self.device).T\n",
    "        else:\n",
    "            theta = torch.tensor(np.array([injection_parameters[paraname] for paraname in self.parameter_names]), dtype=torch.float32).to(self.device).T\n",
    "        return theta\n",
    "    '''\n",
    "\n",
    "    def get_theta(self, injection_parameters):\n",
    "        if self.fix_extrinsic:\n",
    "            parameter_names = ['chirp_mass', 'mass_ratio', 'a_1', 'a_2', 'tilt_1', 'tilt_2', 'phi_12', 'phi_jl',\n",
    "                    'lambda_tilde', 'delta_lambda_tilde', 'theta_jn', 'phase']\n",
    "        else:\n",
    "            parameter_names = self.parameter_names\n",
    "        \n",
    "        theta_list = []\n",
    "        for paraname in parameter_names:\n",
    "            if self.reparameterize:\n",
    "                para_re = reparameterize(injection_parameters[paraname], paraname)\n",
    "            else:\n",
    "                para_re = injection_parameters[paraname]\n",
    "            theta_list.append(para_re)\n",
    "        theta_array = np.array(theta_list)\n",
    "        theta = torch.tensor(theta_array, dtype=torch.float32).to(self.device).T\n",
    "    \n",
    "        return theta\n",
    "    \n",
    "    def update_injection_parameters_batch(self, injection_parameters):\n",
    "        if self.fix_extrinsic:\n",
    "            injection_parameters['ra'] = np.zeros(self.minibatch_size) + 1#np.random.uniform(0, 2*np.pi) #1\n",
    "            injection_parameters['dec'] = np.zeros(self.minibatch_size) + 1#np.arcsin(np.random.uniform(-1, 1)) #1\n",
    "            injection_parameters['psi'] = np.zeros(self.minibatch_size) + 1#np.random.uniform(0, np.pi) #1\n",
    "            injection_parameters['geocent_time'] = np.zeros(self.minibatch_size) \n",
    "            injection_parameters['luminosity_distance'] = np.zeros(self.minibatch_size) + 100\n",
    "    \n",
    "        else:\n",
    "            injection_parameters['ra'] = np.random.uniform(0, 2*np.pi, self.minibatch_size)\n",
    "            injection_parameters['dec'] = np.arcsin(np.random.uniform(-1, 1, self.minibatch_size))\n",
    "            injection_parameters['psi'] = np.random.uniform(0, np.pi, self.minibatch_size)\n",
    "            injection_parameters['geocent_time'] = np.random.uniform(-0.01, 0.01, self.minibatch_size)\n",
    "            injection_parameters['luminosity_distance'] = generate_random_distance(Nsample=self.minibatch_size, low=self.dmin, high=self.dmax, power=self.dpower)\n",
    "        \n",
    "        return injection_parameters\n",
    "    \n",
    "    def shuffle_wflist(self):\n",
    "        #if self.shuffle:\n",
    "        random.shuffle(self.precalwf_filelist)\n",
    "        \n",
    "    def shuffle_indexinfile(self):\n",
    "        if self.shuffle:\n",
    "            self.random_index_in_file = np.random.permutation(self.sample_per_file)\n",
    "        else:\n",
    "            self.random_index_in_file = np.arange(self.sample_per_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "nominated-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_batch_new = DatasetSVDStrainFDFromSVDWFonGPUBatchNew(train_filenames[:3], PARAMETER_NAMES_CONTEXT_PRECESSINGBNS_BILBY, data_generator,\n",
    "                                     Nbasis=512, Vhfile=Vhfile, minibatch_size=4096, device='cuda:1', shuffle=False,\n",
    "                                                     add_noise=False, fix_extrinsic=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "assigned-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "dataset_batch = DatasetSVDStrainFDFromSVDWFonGPUBatch(train_filenames[:1], PARAMETER_NAMES_CONTEXT_PRECESSINGBNS_BILBY, data_generator,\n",
    "                                     Nbasis=512, Vhfile=Vhfile, minibatch_size=64, device='cuda:1', shuffle=False,\n",
    "                                                     add_noise=False, fix_extrinsic=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-stone",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dramatic-evidence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_batch.sample_per_file / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "major-minneapolis",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_batch' is not defined"
     ]
    }
   ],
   "source": [
    "%time theta, x = dataset_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "thrown-schedule",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.31 s, sys: 17.7 ms, total: 1.33 s\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%time theta_new, x_new = dataset_batch_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "spoken-carol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 6, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eastern-drill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4096*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "annual-refrigerator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_batch_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "unlikely-moscow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.9339e-06, device='cuda:1')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x_new-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "confident-current",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically updated cached wf.\n",
      "Automatically updated cached wf.\n",
      "121.71933102607727\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset_batch_new, batch_size=batch_size, shuffle=False)\n",
    "t1 = time.time()\n",
    "i=0\n",
    "for theta, x in dataloader:\n",
    "    i+=1\n",
    "    pass\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "respiratory-parcel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "exact-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "del theta,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "junior-council",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.34587287902832\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "dataloader = DataLoader(dataset_batch, batch_size=batch_size, shuffle=False)\n",
    "t1 = time.time()\n",
    "i=0\n",
    "for theta, x in dataloader:\n",
    "    i+=1\n",
    "    pass\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-protest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-melbourne",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "honey-chess",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-dietary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-institution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-minnesota",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "raised-dubai",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008593760854058718"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.array(resp_and_dt_dict_real['ET3']) - np.array(resp_and_dt_dict['ET3']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "perfect-belle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.32745696756898e-05"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.array(resp_and_dt_dict_real['ET1']) - np.array(resp_and_dt_dict['ET1']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "killing-argentina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0016637406934446874"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.array(resp_and_dt_dict_real['ET2']) - np.array(resp_and_dt_dict['ET2']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-seminar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fewer-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "dddd = np.array(resp_and_dt_dict_real['ET2']) - np.array(resp_and_dt_dict['ET2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "broke-eligibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe26b0802b0>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dddd[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-better",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "integral-birmingham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.65375665e-05, -5.30453516e-05, -2.19071341e-05, -8.06043201e-06,\n",
       "        3.47315427e-05,  3.07125366e-05,  8.66517929e-05,  2.81843600e-05,\n",
       "       -5.43870591e-06, -7.04129506e-05])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_gpu-fp_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "moral-simple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.07599926e-05,  9.71602401e-06,  2.91876699e-05,  8.23354270e-05,\n",
       "        4.93105117e-05,  5.77011522e-06, -3.33246178e-05, -5.21903564e-05,\n",
       "       -2.03484881e-05, -5.99885284e-05])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_gpu-fc_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "utility-trash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.31519273e-15, -8.26338550e-08, -1.48061706e-07,  6.03336825e-15,\n",
       "       -5.53355255e-08, -9.16744686e-08,  6.08540995e-15, -2.79243491e-08,\n",
       "       -4.00779232e-08,  5.50254287e-15])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_gpu - dt_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-vancouver",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-peeing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-republican",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "tough-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GWAntenna():\n",
    "    def __init__(self, detector_name, device='cuda'):\n",
    "        #self.det_bilby = sealgw.simulation.sealinterferometers.SealInterferometerList([detector_name])[0]\n",
    "        self.det_bilby = bilby.gw.detector.InterferometerList([detector_name])[0]\n",
    "        self.location = torch.from_numpy(self.det_bilby.vertex).type(torch.float64)\n",
    "        self.detector_tensor = torch.from_numpy(self.det_bilby.geometry.detector_tensor).type(torch.float64)\n",
    "        \n",
    "        \n",
    "    def response(self, ra, dec, psi, gpstime):\n",
    "        bs = ra.shape[0]\n",
    "        #D = self.detector_tensor.unsqueeze(0).repeat(bs, 1, 1)\n",
    "        D = self.detector_tensor\n",
    "        \n",
    "        X = torch.zeros(bs, 3).type(torch.float64)\n",
    "        Y = torch.zeros(bs, 3).type(torch.float64)\n",
    "\n",
    "        # Greenwich hour angle of source (radians).\n",
    "        # gha = gps2gmst(gpstime) - ra\n",
    "        # The greenwich_mean_sidereal_time / gps2gmst can not be parallized on GPU\n",
    "        # because it in the end needs a builtin fundamental function time.gmtime().\n",
    "        # Therefore we have to make sure that gpstime is (almost) the same in the batch\n",
    "        gha = torch.zeros_like(gpstime) + bilby.gw.utils.greenwich_mean_sidereal_time(gpstime[0]) - ra\n",
    "\n",
    "        # pre-compute trig functions\n",
    "        cosgha = torch.cos(gha)\n",
    "        singha = torch.sin(gha)\n",
    "        cosdec = torch.cos(dec)\n",
    "        sindec = torch.sin(dec)\n",
    "        cospsi = torch.cos(psi)\n",
    "        sinpsi = torch.sin(psi)\n",
    "    \n",
    "        X[:,0] = -cospsi * singha - sinpsi * cosgha * sindec\n",
    "        X[:,1] = -cospsi * cosgha + sinpsi * singha * sindec\n",
    "        X[:,2] =  sinpsi * cosdec\n",
    "\n",
    "        Y[:,0] =  sinpsi * singha - cospsi * cosgha * sindec\n",
    "        Y[:,1] =  sinpsi * cosgha + cospsi * singha * sindec\n",
    "        Y[:,2] =  cospsi * cosdec\n",
    "\n",
    "\n",
    "\n",
    "        #fp = torch.einsum('ij,ijk,ik->i', X, D, X) - torch.einsum('ij,ijk,ik->i', Y, D, Y)\n",
    "        #fc = torch.einsum('ij,ijk,ik->i', X, D, Y) + torch.einsum('ij,ijk,ik->i', Y, D, X)\n",
    "        \n",
    "        fp = torch.einsum('ij,jk,ik->i', X, D, X) - torch.einsum('ij,jk,ik->i', Y, D, Y)\n",
    "        fc = torch.einsum('ij,jk,ik->i', X, D, Y) + torch.einsum('ij,jk,ik->i', Y, D, X)\n",
    "\n",
    "        return fp, fc\n",
    "    \n",
    "    def time_delay_from_geocenter(self, ra, dec, gpstime):\n",
    "        #gmst = gps2gmst(gpstime)\n",
    "        bs = ra.shape[0]\n",
    "        #loc = self.location.unsqueeze(0).repeat(bs, 1)\n",
    "\n",
    "        gmst = torch.zeros_like(gpstime) + bilby.gw.utils.greenwich_mean_sidereal_time(gpstime[0]) #- ra\n",
    "        long = gmst - ra\n",
    "        lat = dec\n",
    "        \n",
    "        wavevector = torch.zeros(bs, 3).type(torch.float64)\n",
    "        wavevector[:,0],wavevector[:,1],wavevector[:,2]  = \\\n",
    "            -torch.cos(long)*torch.cos(lat), -torch.cos(long)*torch.sin(lat), -torch.sin(long)\n",
    "        \n",
    "        print(wavevector.shape)\n",
    "        print(self.location.shape)\n",
    "        #dt = torch.dot(wavevector,self.location.unsqueeze(-1)) / 299792458\n",
    "        #dt = torch.matmul(wavevector, self.location) / 299792458\n",
    "        dt = torch.einsum('ij,j->i', wavevector, self.location) / 299792458\n",
    "        \n",
    "        #dt=1\n",
    "        return dt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myigwn-py39",
   "language": "python",
   "name": "myigwn-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
