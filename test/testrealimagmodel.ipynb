{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "promotional-vienna",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "#from .utils import PARAMETER_NAMES_ALL_PRECESSINGBNS_BILBY\n",
    "from river.models.utils import *\n",
    "from river.data.utils import *\n",
    "\n",
    "import river.data\n",
    "from river.data.datagenerator import DataGeneratorBilbyFD\n",
    "from river.data.dataset import DatasetSVDStrainFDFromSVDWFonGPU #DatasetStrainFD, #DatasetStrainFDFromPreCalSVDWF\n",
    "#import river.data.utils as datautils\n",
    "from river.data.utils import *\n",
    "\n",
    "from river.models import embedding\n",
    "from river.models.utils import *\n",
    "#from river.models.embedding.pca import project_strain_data_FDAPhi\n",
    "from river.models.embedding.conv import EmbeddingConv1D, EmbeddingConv2D\n",
    "from river.models.embedding.mlp import EmbeddingMLP1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "parliamentary-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bilby \n",
    "import pycbc \n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import pickle\n",
    "#from sklearn.utils.extmath import randomized_svd\n",
    "import sklearn\n",
    "from sklearn.decomposition import IncrementalPCA, randomized_svd, KernelPCA\n",
    "import sklearn.decomposition \n",
    "\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "realistic-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "validfolder = '/home/qian.hu/mlpe/training_data/bns_50Hz1024Hz32s_lowspin_lb/valid'\n",
    "trainfolder = '/home/qian.hu/mlpe/training_data/bns_50Hz1024Hz32s_lowspin_lb/train'\n",
    "\n",
    "valid_filenames = glob.glob(f\"{validfolder}/batch*/*.h5\")\n",
    "train_filenames = glob.glob(f\"{trainfolder}/batch*/*.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fallen-start",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:14 bilby INFO    : Waveform generator initiated with\n",
      "  frequency_domain_source_model: bilby.gw.source.lal_binary_neutron_star\n",
      "  time_domain_source_model: None\n",
      "  parameter_conversion: bilby.gw.conversion.convert_to_lal_binary_black_hole_parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bilby_default PSDs to generate data.\n"
     ]
    }
   ],
   "source": [
    "source_type = 'BNS'\n",
    "detector_names = ['H1', 'L1', 'V1'] \n",
    "duration = 32\n",
    "f_low = 50\n",
    "f_high = 1024\n",
    "\n",
    "f_ref = 20\n",
    "sampling_frequency = 2048\n",
    "waveform_approximant = 'IMRPhenomPv2_NRTidal'\n",
    "parameter_names = PARAMETER_NAMES_ALL_PRECESSINGBNS_BILBY\n",
    "PSD_type = 'bilby_default' #'zero_noise' bilby_default\n",
    "use_sealgw_detector = True\n",
    "\n",
    "Vhfile=\"/home/qian.hu/mlpe/river/test/outputs/Vh_50Hz1024Hz32s.pickle\"\n",
    "\n",
    "data_generator = DataGeneratorBilbyFD(source_type,\n",
    "            detector_names, \n",
    "            duration, \n",
    "            f_low, \n",
    "            f_ref, \n",
    "            sampling_frequency, \n",
    "            waveform_approximant, \n",
    "            parameter_names,\n",
    "            PSD_type=PSD_type,\n",
    "            use_sealgw_detector=use_sealgw_detector,\n",
    "            f_high=f_high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accredited-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "\n",
    "dataset = DatasetSVDStrainFDFromSVDWFonGPU(valid_filenames, PARAMETER_NAMES_CONTEXT_PRECESSINGBNS_BILBY, data_generator,\n",
    "                                     Nbasis=512, Vhfile=Vhfile, device=device)\n",
    "\n",
    "batch_size = 4\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "systematic-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, x = dataset[1]\n",
    "\n",
    "for theta_batch, x_batch in dataloader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fleet-species",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "naughty-creator",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embd = EmbeddingConv1D(ndet=3, nout=256, num_blocks=2, use_psd = False).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "desirable-alcohol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 512])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "handled-sympathy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embd.nchannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "becoming-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = embd(x.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "outside-entrance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1,2) == (2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "simplified-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResidualConvBlock2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1):\n",
    "        super().__init__()\n",
    "        #self.padding=padding\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=1, padding=0, dilation=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        \n",
    "        if in_channels != out_channels or kernel_size!=1 or stride!=1 or padding!=0 or dilation!=1:\n",
    "            self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation) \n",
    "        else:\n",
    "            self.downsample = nn.Identity()\n",
    "\n",
    "        '''\n",
    "        self.downsample = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        '''\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.downsample(residual)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class MyEmbeddingConv2D(nn.Module):\n",
    "    def __init__(self, nout, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.nout = nout\n",
    "        self.layers = nn.ModuleList([self.make_layer()])\n",
    "        self.linear = nn.Linear(3, self.nout)\n",
    "\n",
    "    def make_layer(self):\n",
    "        layers = []\n",
    "        layers.append(ResidualConvBlock2D(in_channels=1, out_channels=8,\n",
    "                                          kernel_size=(3,2), stride=(1,1), dilation=(1,1), padding = (2,0)))\n",
    "        layers.append(ResidualConvBlock2D(in_channels=8, out_channels=16,\n",
    "                                          kernel_size=(3,4), stride=(1,1), dilation=(2,1), padding = (2,0)))\n",
    "        layers.append(ResidualConvBlock2D(in_channels=16, out_channels=16,\n",
    "                                          kernel_size=(3,2), stride=(1,1), dilation=(2,1), padding = (2,0)))\n",
    "        layers.append(ResidualConvBlock2D(in_channels=16, out_channels=3,\n",
    "                                          kernel_size=(3,2), stride=(1,1), dilation=(1,1), padding = (2,0)))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : [batch_size, channel (det_123, amp/phase) = 2*ndet, length (number of samples)]\n",
    "        # bs,_,_,_  = x.shape\n",
    "        x = x.unsqueeze(1)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.linear(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "decent-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_batch.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "municipal-horizontal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 6, 512])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "incident-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "embd = MyEmbeddingConv2D(nout=256).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "later-bernard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8726"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-course",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "packed-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Conv2d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "different-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = torch.nn.Conv2d(1, 8, kernel_size=(3,2), stride=(1,1), dilation=(1,1), padding = (2,0)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "brazilian-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = ResidualConvBlock2D(1, 8, kernel_size=(3,2), stride=(4,2), dilation=(3,4), padding = (3,2)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-pepper",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "possible-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = embd(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-tourism",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "chronic-sister",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "conscious-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glasflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "plain-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "glasflow.nflows.nn.nets.ConvResidualNet??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "superb-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Conv2d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "specified-henry",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (255) must match the size of tensor b (512) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-51c2452729a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcondition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/myigwn-py39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-134-5596c64891e8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# bs,_,_,_  = x.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myigwn-py39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myigwn-py39/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myigwn-py39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-134-5596c64891e8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (255) must match the size of tensor b (512) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "condition = embd(x_batch.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "touched-david",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "pressed-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.avg_pool2d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "broadband-passion",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"avg_pool2d\" not implemented for 'ComplexFloat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-d20feb3e905f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0maa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: \"avg_pool2d\" not implemented for 'ComplexFloat'"
     ]
    }
   ],
   "source": [
    "aa = torch.tensor([[[1+1j, 2, 3, 4, 5, 6, 7]]], dtype=torch.complex64)\n",
    "F.avg_pool1d(aa, kernel_size=3, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-envelope",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myigwn-py39",
   "language": "python",
   "name": "myigwn-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
